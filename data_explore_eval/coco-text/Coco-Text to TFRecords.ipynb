{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:01.455737\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import coco_text\n",
    "COCO_DATA='/home/sravya/data/muse/coco/coco2014/'\n",
    "ct = coco_text.COCO_Text(COCO_DATA+ 'COCO_Text.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/sravya/git/models\")\n",
    "from object_detection.utils import dataset_util\n",
    "\n",
    "def writeTF(ImgIds, dataType, out_path):\n",
    "    skipped_boxes = 0\n",
    "    size_mismatch = 0\n",
    "    empty_images = 0\n",
    "    skipped_files = 0\n",
    "\n",
    "    path = '{}{}/'.format(COCO_DATA, dataType)\n",
    "    writer = tf.python_io.TFRecordWriter(out_path)\n",
    "\n",
    "    for imgId in tqdm(ImgIds):\n",
    "        img = ct.loadImgs(imgId)[0]\n",
    "        filename = img['file_name']\n",
    "        pil_img = Image.open(path + filename)\n",
    "        width, height = pil_img.size\n",
    "\n",
    "        #Sanity check\n",
    "        if(width != img['width'] or height != img['height']):\n",
    "            size_mismatch += 1\n",
    "            width = img['width']\n",
    "            height = img['height']    \n",
    "\n",
    "        #Sanity check\n",
    "        if(height == 0 or width == 0):\n",
    "            empty_images += 1\n",
    "            continue\n",
    "\n",
    "        annIds = ct.getAnnIds(imgId)\n",
    "        anns = ct.loadAnns(annIds)\n",
    "\n",
    "        xmins = []\n",
    "        ymins = []\n",
    "        xmaxs = []\n",
    "        ymaxs = []\n",
    "        classes_text = [] # List of string class name of bounding box (1 per box)\n",
    "        classes = []\n",
    "\n",
    "        for ann in anns:\n",
    "            xmin = ann['bbox'][0]\n",
    "            ymin = ann['bbox'][1]\n",
    "            b_width = ann['bbox'][2]\n",
    "            b_height = ann['bbox'][3]\n",
    "            xmax = xmin + b_width\n",
    "            ymax = ymin + b_height\n",
    "\n",
    "            #Normalize\n",
    "            xmin = xmin/width\n",
    "            xmax = xmax/width\n",
    "            ymin = ymin/height\n",
    "            ymax = ymax/height\n",
    "\n",
    "            if(xmin<1 and ymin<1 and xmax<1 and ymax<1):\n",
    "                xmins.append(xmin)\n",
    "                ymins.append(ymin)\n",
    "                xmaxs.append(xmax)\n",
    "                ymaxs.append(ymax)\n",
    "                classes_text.append('Text'.encode('utf8'))\n",
    "                classes.append(1)\n",
    "            else:\n",
    "                skipped_boxes +=1\n",
    "\n",
    "        with tf.gfile.GFile((path + filename), 'rb') as fid:\n",
    "            encoded_image_data = fid.read()\n",
    "        filename = path + filename\n",
    "        filename = filename.encode('utf8')\n",
    "        image_format = b'jpg'\n",
    "\n",
    "        if (len(xmins) != 0):\n",
    "            tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image/height': dataset_util.int64_feature(height),\n",
    "            'image/width': dataset_util.int64_feature(width),\n",
    "            'image/filename': dataset_util.bytes_feature(filename),\n",
    "            'image/source_id': dataset_util.bytes_feature(filename),\n",
    "            'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "            'image/format': dataset_util.bytes_feature(image_format),\n",
    "            'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "            'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "            'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "            'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "            'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "            'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "            }))\n",
    "            writer.write(tf_example.SerializeToString())        \n",
    "        else:\n",
    "            skipped_files += 1\n",
    "    print('skipped_boxes:{} size_mismatch: {} empty_images: {} skipped_files: {}'.format(\n",
    "        skipped_boxes, size_mismatch, empty_images, skipped_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_record = '/home/sravya/data/muse/coco/coco2014/TF/training.record'\n",
    "train_dir='train2014'\n",
    "valid_record = '/home/sravya/data/muse/coco/coco2014/TF/valid.record'\n",
    "#val_dir='val2014'\n",
    "\n",
    "train_img_ids = ct.getImgIds(imgIds=ct.train, catIds=[('legibility','legible')])\n",
    "valid_img_ids = ct.getImgIds(imgIds=ct.val, catIds=[('legibility','legible')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15124/15124 [00:06<00:00, 2373.63it/s]\n",
      "  7%|▋         | 230/3522 [00:00<00:01, 2298.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped_boxes:0 size_mismatch: 0 empty_images: 0 skipped_files: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3522/3522 [00:01<00:00, 2413.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped_boxes:0 size_mismatch: 0 empty_images: 0 skipped_files: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "writeTF(train_img_ids, train_dir, training_record)\n",
    "writeTF(valid_img_ids, train_dir, valid_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "118px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
