{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sanitization\n",
    "1. Some files have more boxes than texts\n",
    "2. Orientated boxes need to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'synth_utils' from '/home/sravya/git/Muse_Deliverable/synth_utils.py'>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH='/home/sravya/data/muse/'\n",
    "SYNTH_HOME = DATA_PATH+'SynthText/SynthText/'\n",
    "PROCESSED = SYNTH_HOME + 'processed/'\n",
    "NON_ORIENTED = SYNTH_HOME + 'non_oriented/'\n",
    "import synth_utils\n",
    "import importlib\n",
    "importlib.reload(synth_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove files that have more boxes than texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove files that have more boxes than texts and save new imnames,texts and boxes as numpy arrays to disk at ./processed\n",
    "save_clean_inputs(SYNTH_HOME)    \n",
    "#TODO: Clean up this utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove oriented boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "wordBB = np.load(SYNTH_HOME + 'processed/wordBB.npy')\n",
    "imnames = np.load(SYNTH_HOME + 'processed/imnames.npy')\n",
    "text = np.load(SYNTH_HOME + 'processed/text.npy')\n",
    "\n",
    "good_boxes = 0\n",
    "bad_boxes = 0\n",
    "file_boxes = []\n",
    "file_texts = []\n",
    "files = []\n",
    "\n",
    "for index, file in enumerate(wordBB):\n",
    "    boxes = []\n",
    "    texts = []\n",
    "    for bb in list(range(file.shape[-1])):\n",
    "\n",
    "        xmin = file[0][0][bb]\n",
    "        xmax = file[0][2][bb]\n",
    "        ymin = file[1][0][bb]\n",
    "        ymax = file[1][2][bb]\n",
    "        if xmin<xmax and  ymin>ymax:\n",
    "            good_boxes += 1\n",
    "            boxes.append((xmin,ymin,xmax,ymax))\n",
    "            texts.append(text[index][bb])\n",
    "            box_indices.append(bb)            \n",
    "        else:\n",
    "            bad_boxes += 1\n",
    "    if(len(boxes) != 0):\n",
    "        files.append(imnames[index])\n",
    "        file_boxes.append(boxes)\n",
    "        file_texts.append(boxes)\n",
    "#Save new set of imnames, boxes and texts\n",
    "synth_utils.numpysave(NON_ORIENTED, files, file_boxes, file_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83627, 83627, 83627)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_boxes), len(file_texts), len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162030, 1573031)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_boxes, bad_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_boxes = 0\n",
    "for boxes in file_boxes:\n",
    "    num_boxes += len(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162030"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_boxes = 0\n",
    "for boxes in file_texts:\n",
    "    num_boxes += len(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162030"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CreateTF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "files = np.load(NON_ORIENTED + 'imnames.npy')\n",
    "file_boxes = np.load(NON_ORIENTED + 'wordBB.npy')\n",
    "file_texts = np.load(NON_ORIENTED + 'text.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/sravya/git/models\")\n",
    "from object_detection.utils import dataset_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "from PIL import Image\n",
    "PATH=DATA_PATH+'SynthText/SynthText_split/'\n",
    "def create_tf_record(filename, wordBB, text):\n",
    "    \"\"\" returns TFRecord for each file\"\"\"\n",
    "    img = Image.open(PATH + filename)\n",
    "    width, height = img.size\n",
    "    #Add zero check\n",
    "    with tf.gfile.GFile((PATH + filename), 'rb') as fid:\n",
    "        encoded_image_data = fid.read()\n",
    "    filename = filename.encode('utf8')\n",
    "\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    ymins = []\n",
    "    xmaxs = []\n",
    "    ymaxs = []\n",
    "    classes_text = [] # List of string class name of bounding box (1 per box)\n",
    "    classes = []\n",
    "        \n",
    "    for index, bb in enumerate(wordBB):\n",
    "        #print(bb[0],bb[1],bb[2],bb[3])\n",
    "        x_min, y_min, x_max, y_max = bb[0]/width, bb[1]/height,bb[2]/width, bb[3]/height\n",
    "        #Make sure bb lies within the image\n",
    "        #print(x_min,y_min,x_max,y_max)\n",
    "        if(x_min < 1 and y_min <1 and x_max <1 and y_max <1):\n",
    "            xmins.append(x_min)\n",
    "            ymins.append(y_min)\n",
    "            xmaxs.append(x_max)\n",
    "            ymaxs.append(y_max)\n",
    "            classes_text.append('Text'.encode('utf8'))\n",
    "            classes.append(1)\n",
    "    #print(xmins,xmaxs,ymins,ymaxs)\n",
    "#     #Sanity check none of the values are Nans\n",
    "#     if not np.all(np.isfinite(xmins)):\n",
    "#         print(xmins)\n",
    "#     if not np.all(np.isfinite(ymins)):\n",
    "#         print(ymins)\n",
    "#     if not np.all(np.isfinite(xmaxs)):\n",
    "#         print(ymaxs)\n",
    "        \n",
    "    if (len(xmins) != 0):\n",
    "        tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "  }))\n",
    "    else:\n",
    "        #print('Skipped filename: ' + str(filename))\n",
    "        return None\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83627"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83627"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "indices = list(range(0,len(files)))\n",
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19984, 67635]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58538/58538 [00:20<00:00, 2854.35it/s]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "skipped = 0\n",
    "writer = tf.python_io.TFRecordWriter('data/training.record')\n",
    "for index in tqdm(indices[:58538], total=58538):\n",
    "    tf_record = create_tf_record(files[index][0], file_boxes[index], file_texts[index])\n",
    "    if tf_record is not None:\n",
    "        writer.write(tf_record.SerializeToString())\n",
    "    else:\n",
    "        skipped += 1\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16726/16726 [00:05<00:00, 3108.78it/s]\n"
     ]
    }
   ],
   "source": [
    "writer = tf.python_io.TFRecordWriter('data/valid.record')\n",
    "for index in tqdm(indices[58538:75264], total=16726):\n",
    "    tf_record = create_tf_record(files[index][0], file_boxes[index], file_texts[index])\n",
    "    if tf_record is not None:\n",
    "        writer.write(tf_record.SerializeToString())\n",
    "    else:\n",
    "        skipped += 1\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1185"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8363/8363 [00:02<00:00, 3092.44it/s]\n"
     ]
    }
   ],
   "source": [
    "writer = tf.python_io.TFRecordWriter('data/test.record')\n",
    "for index in tqdm(indices[75264:83627], total=8363):\n",
    "    tf_record = create_tf_record(files[index][0], file_boxes[index], file_texts[index])\n",
    "    if tf_record is not None:\n",
    "        writer.write(tf_record.SerializeToString())\n",
    "    else:\n",
    "        skipped += 1\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1307"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Move all files into split folder\n",
    "from random import shuffle\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "sample_files = glob(DATA_PATH+'SynthText/SynthText_sample/*/*')\n",
    "len(sample_files)\n",
    "\n",
    "for path in sample_files:\n",
    "    newfile = path.replace('sample','split')\n",
    "    os.renames(path,newfile)\n",
    "    print(path,newfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.text()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "100px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
